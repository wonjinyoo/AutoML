{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZHZ3BHlSmQ4pNqf6109qH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjinyoo/AutoML/blob/main/FLAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q flaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc-Vla3o-YHz",
        "outputId": "72406ed2-e5c0-464f-9e0c-35f4a5ac453e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/296.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/296.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECUiL3hG-A0b",
        "outputId": "42058dc4-2f5b-4b68-ff70-bc63098fbbb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 07-12 03:29:54] {1680} INFO - task = classification\n",
            "[flaml.automl.logger: 07-12 03:29:54] {1691} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 07-12 03:29:54] {1789} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl.logger: 07-12 03:29:54] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2345} INFO - Estimated sufficient time budget=712s. Estimated necessary time budget=16s.\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.6s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.7s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2392} INFO -  at 0.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:54] {2219} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 0.9s,\testimator extra_tree's best error=0.1533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.2s,\testimator extra_tree's best error=0.1533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.3s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 19, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.4s,\testimator rf's best error=0.0867,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 20, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.6s,\testimator rf's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.7s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:55] {2219} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 1.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.0s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.3s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.5s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2392} INFO -  at 2.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:56] {2219} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 2.8s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.0s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.2s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 37, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.3s,\testimator rf's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.4s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.5s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.6s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2392} INFO -  at 3.7s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:57] {2219} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 3.9s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.0s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 49, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.4s,\testimator rf's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.5s,\testimator xgboost's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2392} INFO -  at 4.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:58] {2219} INFO - iteration 55, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2392} INFO -  at 4.9s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2219} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2392} INFO -  at 5.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2219} INFO - iteration 57, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2392} INFO -  at 5.3s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2219} INFO - iteration 58, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2392} INFO -  at 5.6s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:29:59] {2219} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:00] {2392} INFO -  at 6.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:00] {2219} INFO - iteration 60, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:00] {2392} INFO -  at 6.7s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:00] {2219} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2392} INFO -  at 6.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2219} INFO - iteration 62, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2392} INFO -  at 7.0s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2219} INFO - iteration 63, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2392} INFO -  at 7.3s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2219} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2392} INFO -  at 7.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2219} INFO - iteration 65, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2392} INFO -  at 7.7s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:01] {2219} INFO - iteration 66, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2392} INFO -  at 7.8s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2219} INFO - iteration 67, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2392} INFO -  at 8.1s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2219} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2392} INFO -  at 8.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2219} INFO - iteration 69, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2392} INFO -  at 8.3s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2219} INFO - iteration 70, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2392} INFO -  at 8.6s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:02] {2219} INFO - iteration 71, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 8.8s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 72, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.0s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 73, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.2s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.3s,\testimator xgboost's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.5s,\testimator xgboost's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 78, current learner rf\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2392} INFO -  at 9.7s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:03] {2219} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2392} INFO -  at 9.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2219} INFO - iteration 80, current learner extra_tree\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2392} INFO -  at 10.0s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2219} INFO - iteration 81, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2392} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.0500,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2628} INFO - retrain lgbm for 0.0s\n",
            "[flaml.automl.logger: 07-12 03:30:04] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.9712608239851066,\n",
            "               learning_rate=0.5066472382072831, max_bin=63,\n",
            "               min_child_samples=9, n_estimators=1, n_jobs=-1, num_leaves=4,\n",
            "               reg_alpha=0.008673969948933881, reg_lambda=0.47452813352268625,\n",
            "               verbose=-1)\n",
            "[flaml.automl.logger: 07-12 03:30:04] {1931} INFO - fit succeeded\n",
            "[flaml.automl.logger: 07-12 03:30:04] {1932} INFO - Time taken to find the best model: 0.38747358322143555\n",
            "[[0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.81927853 0.15011003 0.03061144]\n",
            " [0.7725578  0.20229926 0.02514294]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.94986785 0.0227757  0.02735645]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.81927853 0.15011003 0.03061144]\n",
            " [0.7725578  0.20229926 0.02514294]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.95482095 0.02289446 0.02228459]\n",
            " [0.03532049 0.90765492 0.05702459]\n",
            " [0.02426335 0.94561863 0.03011802]\n",
            " [0.02979822 0.76574527 0.20445651]\n",
            " [0.02425689 0.94536674 0.03037637]\n",
            " [0.02426335 0.94561863 0.03011802]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.04597815 0.88593955 0.0680823 ]\n",
            " [0.03444868 0.93549223 0.03005908]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.03444868 0.93549223 0.03005908]\n",
            " [0.02426335 0.94561863 0.03011802]\n",
            " [0.03444868 0.93549223 0.03005908]\n",
            " [0.03532049 0.90765492 0.05702459]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02426335 0.94561863 0.03011802]\n",
            " [0.03464616 0.94085506 0.02449878]\n",
            " [0.02409355 0.93900101 0.03690544]\n",
            " [0.02425689 0.94536674 0.03037637]\n",
            " [0.05607781 0.22602748 0.71789471]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02979822 0.76574527 0.20445651]\n",
            " [0.03532049 0.90765492 0.05702459]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.03421511 0.8792491  0.08653579]\n",
            " [0.04750441 0.10416041 0.84833518]\n",
            " [0.02426335 0.94561863 0.03011802]\n",
            " [0.03464616 0.94085506 0.02449878]\n",
            " [0.02425689 0.94536674 0.03037637]\n",
            " [0.03444868 0.93549223 0.03005908]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.05448352 0.24041868 0.70509779]\n",
            " [0.02426335 0.94561863 0.03011802]\n",
            " [0.03209893 0.93802491 0.02987616]\n",
            " [0.03487663 0.89624882 0.06887455]\n",
            " [0.02425689 0.94536674 0.03037637]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02425689 0.94536674 0.03037637]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.03444868 0.93549223 0.03005908]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.20190513 0.77324896 0.02484591]\n",
            " [0.02439742 0.95084371 0.02475887]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02748767 0.04665313 0.9258592 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.06616033 0.26666613 0.66717354]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02748767 0.04665313 0.9258592 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.04750441 0.10416041 0.84833518]\n",
            " [0.02748767 0.04665313 0.9258592 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.06077965 0.52218884 0.41703151]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.0436898  0.17609634 0.78021386]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.0436898  0.17609634 0.78021386]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.05607781 0.22602748 0.71789471]\n",
            " [0.0436898  0.17609634 0.78021386]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.04765475 0.16284178 0.78950347]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.05448352 0.24041868 0.70509779]\n",
            " [0.04765475 0.16284178 0.78950347]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.05607781 0.22602748 0.71789471]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02748767 0.04665313 0.9258592 ]\n",
            " [0.02748767 0.04665313 0.9258592 ]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.04750441 0.10416041 0.84833518]\n",
            " [0.02201018 0.02892832 0.9490615 ]\n",
            " [0.02913985 0.02871742 0.94214272]\n",
            " [0.02748767 0.04665313 0.9258592 ]]\n",
            "<flaml.automl.model.LGBMEstimator object at 0x7f37cf881c00>\n"
          ]
        }
      ],
      "source": [
        "from flaml import AutoML\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "automl = AutoML()\n",
        "\n",
        "# automl 목표, 제약조건 설정\n",
        "automl_settings = {\n",
        "    \"time_budget\": 10,  # 10초 단위\n",
        "    \"metric\": 'accuracy',\n",
        "    \"task\": 'classification',\n",
        "}\n",
        "\n",
        "X_train, y_train = load_iris(return_X_y=True)\n",
        "\n",
        "# 모델 학습\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# 모델 추론\n",
        "print(automl.predict_proba(X_train))\n",
        "\n",
        "# 가장 좋은 모델 추출\n",
        "print(automl.model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mb-IG1n-_XGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}